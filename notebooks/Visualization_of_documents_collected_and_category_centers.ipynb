{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *Visualization of documents collected and category centers*"
      ],
      "metadata": {
        "id": "fotq6SJt4mTA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltkiDTm_4k-9"
      },
      "outputs": [],
      "source": [
        "!pip install pymongo sentence-transformers torch scikit-learn umap-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient"
      ],
      "metadata": {
        "id": "X-wQ2McB4vcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the JSON file\n",
        "articles = pd.read_json(\"/content/dataset.news_articles.json\")  # Replace with your JSON file name\n",
        "\n",
        "# Inspect the first few rows\n",
        "print(articles.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "QdIpRSkv4w6d",
        "outputId": "3a636b8a-72a1-4414-913c-e1b698374033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xce in position 296747007: unexpected end of data",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a22757d49aae>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0marticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/dataset.news_articles.json\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with your JSON file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Inspect the first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mconvert_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     json_reader = JsonReader(\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ujson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xce in position 296747007: unexpected end of data"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure columns 'text' and 'assigned_category' are present\n",
        "if 'text' not in articles.columns or 'assigned_category' not in articles.columns:\n",
        "    raise ValueError(\"Required columns ('text', 'assigned_category') are missing.\")"
      ],
      "metadata": {
        "id": "c4tEj9doHklK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SBERT model\n",
        "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
      ],
      "metadata": {
        "id": "4Che68vUGxA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for articles' text\n",
        "articles['text_embedding'] = articles['text'].apply(lambda x: model.encode(x, convert_to_tensor=False))\n",
        "\n",
        "# Convert embeddings to a numpy array\n",
        "text_embeddings = np.stack(articles['text_embedding'].to_list())"
      ],
      "metadata": {
        "id": "ZRWCgbcPGpic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categories and their keywords\n",
        "iptc_categories = [\n",
        "    {\"name\": \"Τέχνες, Πολιτισμός, Ψυχαγωγία και Μέσα\", \"keywords\": [\"Τέχνες, Πολιτισμός, Ψυχαγωγία και Μέσα\", \"μουσική\", \"θέατρο\", \"τέχνες\", \"ιστορία\", \"μουσεία\", \"βιβλίο\", \"παραστάσεις\", \"σινεμά\"]},\n",
        "    {\"name\": \"Διαμάχη, Πόλεμος, Ειρήνη\", \"keywords\": [\"Διαμάχη, Πόλεμος, Ειρήνη\", \"τρομοκρατία\", \"πραξικόπημα\", \"πόλεμος\", \"θύματα πολέμου\", \"εμπόλεμη ζώνη\", \"στρατός\"]},\n",
        "    {\"name\": \"Έγκλημα, Νόμος, Δικαιοσύνη\", \"keywords\": [\"Έγκλημα, Νόμος, Δικαιοσύνη\", \"παρενόχληση\", \"έγκλημα\", \"δικαστήριο\", \"βανδαλισμοί\", \"δίκαιο\", \"νομική\"]},\n",
        "    {\"name\": \"Καταστροφή, Ατύχημα, Επείγον Περιστατικό\", \"keywords\": [\"Καταστροφή, Ατύχημα, Επείγον Περιστατικό\", \"έκρηξη\", \"πνιγμός\", \"ατύχημα\", \"δυστύχημα\", \"καταστροφή\"]},\n",
        "    {\"name\": \"Οικονομία, Επιχειρήσεις\", \"keywords\": [\"Οικονομία, Επιχειρήσεις\", \"αγορά\", \"επιχειρήσεις\", \"επενδύσεις\", \"οικονομία\"]},\n",
        "    {\"name\": \"Εκπαίδευση\", \"keywords\": [\"Εκπαίδευση\", \"παιδεία\", \"μαθητές\", \"φοιτητές\", \"δάσκαλοι\", \"καθηγητές\", \"μάθηση\", \"σχολείο\", \"πανεπιστήμιο\", \"ΑΕΙ\", \"ΤΕΙ\", \"ΙΕΚ\"]},\n",
        "    {\"name\": \"Περιβάλλον\", \"keywords\": [\"Περιβάλλον\", \"κλιματική αλλαγή\", \"μόλυνση περιβάλλοντος\", \"φύση\", \"ανανεώσιμες πηγές\"]},\n",
        "    {\"name\": \"Υγεία\", \"keywords\": [\"Υγεία\", \"ασθένεια\", \"περίθαλψη\", \"ασφάλιση\", \"ιδιωτική ασφάλιση\", \"δημόσια ασφάλιση\", \"υγεία\", \"θεραπεία\", \"νοσοκομείο\", \"νοσηλευτές\", \"ιατροί\"]},\n",
        "    {\"name\": \"Εργασία\", \"keywords\": [\"Εργασία\", \"εργασιακά\", \"αγορά εργασίας\", \"ανεργία\", \"σύνταξη\", \"συνταξιοδότηση\"]},\n",
        "    {\"name\": \"Lifestyle\", \"keywords\": [\"καλή ζωή\", \"τρόπος ζωής\", \"lifestyle\", \"ελεύθερος χρόνος\"]},\n",
        "    {\"name\": \"Πολιτική\", \"keywords\": [\"Πολιτική\", \"εκλογές\", \"κόμματα\", \"κυβέρνηση\", \"αντιπολίτευση\", \"διεθνείς σχέσεις\", \"πολιτικά\", \"βουλή\", \"κοινοβούλιο\", \"βουλευτές\", \"πρωθυπουργός\", \"πρόεδρος\"]},\n",
        "    {\"name\": \"Θρησκεία\", \"keywords\": [\"Θρησκεία\", \"θρησκευτική διαμάχη\", \"θεός\", \"εκκλησία\", \"τελετή\", \"αιρέσεις\", \"χριστιανισμός\", \"μουσουλμανισμός\"]},\n",
        "    {\"name\": \"Επιστήμη και Τεχνολογία\", \"keywords\": [\"Επιστήμη και Τεχνολογία\", \"βιοϊατρική επιστήμη\", \"μαθηματικά\", \"φυσική επιστήμη\", \"επιστημονικό ίδρυμα\", \"έρευνα\", \"τεχνολογία\", \"τεχνητή νοημοσύνη\", \"υπολογιστής\"]},\n",
        "    {\"name\": \"Κοινωνία\", \"keywords\": [\"Κοινωνία\", \"κοινωνίες\", \"ισότητα\", \"δικαιώματα\", \"αξίες\", \"μετανάστευση\", \"δημογραφικά\", \"διακρίσεις\", \"οικογένεια\"]},\n",
        "    {\"name\": \"Αθλητισμός\", \"keywords\": [\"αναβολικά\", \"επίτευγμα αθλητή\", \"διάκριση αθλητή\", \"μετάλλιο\", \"αθλητικό γεγονός\", \"αθλητική οργάνωση\", \"προπονητική\", \"αθλητισμός\", \"αθλήματα\"]},\n",
        "    {\"name\": \"Καιρός\", \"keywords\": [\"Καιρός\", \"πρόγνωση καιρού\", \"στατιστική καιρού\", \"προειδοποίηση καιρικών φαινομένων\", \"βροχές\", \"καταιγίδες\"]}\n",
        "            # Add your categories and keywords\n",
        "]\n",
        "\n",
        "# Embed IPTC categories by averaging their keyword embeddings\n",
        "category_embeddings = {\n",
        "    category: np.mean(model.encode(keywords, convert_to_tensor=False), axis=0)\n",
        "    for category, keywords in iptc_categories.items()\n",
        "}\n",
        "\n",
        "# Convert category embeddings to a numpy array\n",
        "category_embedding_array = np.array(list(category_embeddings.values()))"
      ],
      "metadata": {
        "id": "AaPmK6S4GsPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save embeddings and metadata\n",
        "np.save(\"text_embeddings.npy\", text_embeddings)\n",
        "np.save(\"category_embeddings.npy\", category_embedding_array)\n",
        "with open(\"category_names.json\", \"w\") as f:\n",
        "    json.dump(list(category_embeddings.keys()), f)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"sbert_greek_model\")"
      ],
      "metadata": {
        "id": "8KAIUwYz4w4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine text and category embeddings for visualization\n",
        "all_embeddings = np.vstack([text_embeddings, category_embedding_array])\n",
        "\n",
        "# Perform t-SNE to reduce dimensionality\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "reduced_embeddings = tsne.fit_transform(all_embeddings)\n",
        "\n",
        "# Split reduced embeddings\n",
        "text_reduced = reduced_embeddings[:len(text_embeddings)]\n",
        "category_reduced = reduced_embeddings[len(text_embeddings):]"
      ],
      "metadata": {
        "id": "QLlfGtzGEeqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot texts and categories\n",
        "plt.figure(figsize=(12, 8))\n",
        "colors = plt.cm.get_cmap(\"tab10\", len(category_names))\n",
        "\n",
        "# Plot articles\n",
        "for i, category in enumerate(category_names):\n",
        "    indices = articles[articles['assigned_category'] == category].index\n",
        "    plt.scatter(\n",
        "        text_reduced[indices, 0],\n",
        "        text_reduced[indices, 1],\n",
        "        label=f\"Articles: {category}\",\n",
        "        alpha=0.5,\n",
        "        s=20,\n",
        "        color=colors(i),\n",
        "    )\n",
        "\n",
        "# Plot category centers\n",
        "for i, (category, coord) in enumerate(zip(category_names, category_reduced)):\n",
        "    plt.scatter(\n",
        "        coord[0],\n",
        "        coord[1],\n",
        "        label=f\"Category Center: {category}\",\n",
        "        s=200,\n",
        "        color=colors(i),\n",
        "        edgecolor=\"black\",\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"2D Visualization of Articles and IPTC Categories\")\n",
        "plt.xlabel(\"Dimension 1\")\n",
        "plt.ylabel(\"Dimension 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yPBqCRVS4wrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.savefig(\"articles_categories_visualization.png\", dpi=300)"
      ],
      "metadata": {
        "id": "HJz_Rj7q46LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_1wHdbt46Eg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}